{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NASA article\n",
    "# Scrape the site using the URL\n",
    "url = 'https://mars.nasa.gov/news/'\n",
    "\n",
    "# Retrieve page with the requests module\n",
    "html = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "nasa_soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results and look for a div withe the class 'content_title'\n",
    "results = nasa_soup.find_all('div', class_='content_title')\n",
    "\n",
    "# Access the thread's text content\n",
    "news_title=(results[0]).a.text\n",
    "news_title=news_title.replace('\\n', '')\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results and look for a div withe the class 'rollver_description_inner'\n",
    "results = nasa_soup.find('div', class_='rollover_description_inner').text\n",
    "text_content=results.replace('\\n', '')\n",
    "text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [C:\\Users\\saman\\.wdm\\drivers\\chromedriver\\win32\\87.0.4280.88\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "#JPL image\n",
    "#initialize chrome driver\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set url for scraping\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "jpl_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements of the button fancybox\n",
    "results = jpl_soup.find('a', class_='fancybox')\n",
    "\n",
    "#Save image url\n",
    "href=results.get('data-fancybox-href')\n",
    "featured_image_url=f'https://www.jpl.nasa.gov{href}'\n",
    "featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mars fact\n",
    "#Get html for page\n",
    "url = 'https://space-facts.com/mars/'\n",
    "\n",
    "#Get results\n",
    "results=pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write facts table to html\n",
    "mars_facts=results[0].to_html()\n",
    "mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set url for astrogeology\n",
    "url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif/full.jpg'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif/full.jpg'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif/full.jpg'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif/full.jpg'}]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HTML object\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all elements of the button fancybox\n",
    "results = soup.find_all('div', class_='item')\n",
    "\n",
    "#Define dictionary\n",
    "hemisphere_dict=[]\n",
    "\n",
    "for div in results:\n",
    "    # Use Beautiful Soup's find() method to navigate and retrieve attributes\n",
    "    h3 = div.find('h3')\n",
    "    link = div.find('a')\n",
    "    href = link['href']\n",
    "    \n",
    "    # Loop through image links\n",
    "    try:\n",
    "        #Go to web page\n",
    "        browser.visit('https://astrogeology.usgs.gov' + href)\n",
    "    \n",
    "        #HTML object\n",
    "        html=browser.html\n",
    "        \n",
    "        #Parse HTML with Beautiful Soup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        #Retrieve all images\n",
    "        results = soup.find('div', class_='downloads')\n",
    "        image_url = results.find('li').a['href']\n",
    "\n",
    "    #Create Dictionary to store title and url info\n",
    "        image_dict = {}\n",
    "        image_dict['title'] = h3.text\n",
    "        image_dict['img_url'] = image_url\n",
    "        hemisphere_dict.append(image_dict)\n",
    "    \n",
    "    except:\n",
    "        print(\"Scraping Complete\")\n",
    "        \n",
    "hemisphere_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
